---
layout: post
title:  "端到端之CTC理解"
date:   2021-10-10 15:19:01 +0800
categories: ASR E2E
typora-root-url: ..
---

## CTC序列建模

如果去做一个语音识别的任务，给定音频$X$和对应标注$Y$，因为对于每一条音频及其标注$X$与$Y$的长度都是变化不等的，那么如何去考虑音频与标注文本之间的对应关系？

<img src="/assets/images/202110101634025439.png" alt="img" style="zoom:80%;" />

利用CTC可以直接对序列数据进行学习，不需要帧级别的标注，而在输出序列(CTC序列)和最终标签(CTC规整序列)之间增加了多对一的空间映射，并在此基础上定义了损失函数，在训练的过程中自动对齐并使损失函数最小化。

定义$L$​​​​​为建模单元集，建模单元可以是字符，如英文字母{a,b,c...,z}，也可以是音素，也可以是汉字。为了对静音、字间停顿、字间混淆进行建模，CTC引入了额外的空白符标签blank"-"，把建模单元集$L$​​​​扩展为$L^{'}$​​​​(即$L^{'}=L\bigcup blank $​​​​​)，在识别的最后再将空白符剔除。

假设训练集为$S$​​​​，每个样本$（X，Y）$​​​​由输入序列$X={x_1,x_2,...,x_T}$​​​​和输出序列$Y=y_1,y_2,...,y_U$​​​​组成，其中$T$​​​​为输入序列的长度,U则是输出序列的长度，$Y$​​​​的每个标注来自于建模单元集$L$​​​​，CTC的训练目标是是$X$​​​​和$Y$​​​​尽量匹配，即最大化后验概率$P(Y\mid X)$​​​​​​，输入的序列经过解码之后，通过CTC衡量其和正确的序列是否接近。

我们提到过上述的输出序列$Y$其实是经过规整过后的字符串序列，那么输出序列$Y$可能是通过各种CTC路径$A_{ctc}(X,Y)$​​​ 规整后生成的，这些路径包含了标注重复与空白标签blank的各种可能组合，例如，对于输出序列abc，可能由以下CTC路径生成：

- aabbbc

- abbccc

- a-bbb-c

- -a-b-c

- -abb-c

其中“-”为blank表示空白符号，多个连续重复字符表示连续多帧特征均对应同一个字符，如aa表示为一个a，如果要表示aa则中间需要加入空白符如"a-a"

穷举所有**可能的**CTC路径$A_{ctc}(X,Y)$​​，则$Y$​​由$X$​​生成的概率为：


$$
P(Y\mid X)=\sum_{\hat{Y}\in A_{ctc}(X,Y)}P(\hat{Y}\mid X) \tag{1.1}
$$


其中，$\hat{Y}$​​表示$X$​​和$Y$​​在CTC网络下的其中某一条对齐路径，其长度和输入序列$X$​​一致，即$\hat{Y}={\hat{y}_1,\hat{y}_2...,\hat{y}_T}$​​。由$\hat{Y}$​​去除重复和空白标签后我们可以得到规整字符串序列$Y$​​

路径$\hat{Y}$出现的概率是每个时刻的输出概率的乘积：


$$
P(\hat{Y}\mid X) = \prod_{t=1}^TP(\hat{y}_t\mid x_t),\forall \hat{Y}\in{L^{'T}} \tag{1.2}
$$




其中，$\hat{y}$​​​表示路径 $\hat{Y}$​​​在$t$​​​时刻的输出标签($L^{’}$​中的一个)， $P(\hat{y}_t\mid x_t)$​是其对应的输出概率。则上式表示整条CTC路径$\hat{Y}$​的出现概率为从$0$​到$T$​每个时刻输出概率的乘积。

假设扩展建模单元集$L^{'}$的个数为K，则CTC输出层对应K个节点。每个节点的最后输出$p_t^{k}$对应$t$时刻第k个建模单元的概率，其是由Encoder的隐藏层输出$h_t^{k}$经过Softmax函数转换得到的：


$$
p_t^k=\frac{e^{h_t^k}}{\sum_{k=1}^Ke{h_t^k}} \tag{1.3}
$$



对于在某个时刻的输出$\hat{y}_t$​ ，根据其在建模单元集的索引选择K个输出值的其中一个，如果对应的索引为3，则其值为$p_t^3$​，即$P(\hat{y}_t\mid x_t)=p_t^3$​​

基于输入序列$X$，CTC的某条对齐路径$\hat{Y}$的输出概率$P(\hat{Y}\mid X)$​​完整的计算过程如下图所示：

<img src="/assets/images/20211012195213.png" style="zoom:80%;" />

针对输入序列$X={x_1,x_2,...x_T}$​​，令其每一帧分别通过RNN模型得到隐藏层输出${h_1^{\hat{y}_1},h_2^{\hat{y}_2},...h_T^{\hat{y}_T}}$​​，再通过softmax转换得到每一帧的输出概率$p_t^{\hat{y}_t}$​​，再将这些概率连乘得到$P(\hat{Y}\mid X)$​​，即公式(1.2)​​

又因为$X$​与$Y$​之间可能有多条对齐路径，分别单独计算概率后，将所有可能路径概率相加得到总概率$P(Y\mid X)$​，即公式(1.1)​​

## CTC Loss计算

CTC的本质上还是声学模型，其损失函数被定义为训练集$S$所有样本的负对数概率之和：

$$
L(S)=-\sum_{(X,Y)\in S}lnP(Y\mid X) \tag{1.4}
$$


CTC训练优化的目标是使$L(S)$最小化，但计算$P(Y\mid X)$的复杂的非常高，为简化计算过程，可参照HMM的前向后向算法来求解CTC的局部和全局概率。

### 前向算法

在输出序列$Y=y_1,y_2,...,y_U$​的**句子**头尾和每个标签中间添加空白符，表示为$Y^{'}$​​，即$Y^{'}={b,y_1,b,y_2,...，y_U,b}\Rightarrow y_1^{'},y_2^{'},...y_{2U+1}^{'}$​ 

其中$b$​表示空白符，$Y$​的长度为$U$​，则$Y^{'}$​的长度为$2U+1$​​。引入$\alpha_t(s)$来表示已经输出部分观察值$x_1,x2,..x_t$，并且到达标签为s的状态的概率：
$$
\alpha_t(s)=P(x_1,x_2,..x_t,s) \tag{1.5}
$$
前向算法按输入序列的时间顺序，从前向后地推计算输出概率。具体计算步骤如下：

#### 初始化：

$$
\begin{align}
\alpha_1(1)&=P(b\mid x_1) \\
\alpha_1(2)&=P(y^{'}\mid x_1) \\        
\alpha_1(s)&=0, \forall s>2   \\
\end{align}
\tag{1.6}
$$

#### 迭代计算：

$$
\alpha_{t+1}(s)=
\begin{cases}
(\alpha_t(s)+\alpha_t(s-1))P(y^{'}\mid x_t)\space, if\space y_s^{'}=b \space or \space y_{s-2}^{'}=y_s^{'} \\
(\alpha_t(s)+\alpha_t(s-1)+\alpha_t(s-2))P(y^{'}\mid x_t),\space otherwise
\end{cases} \tag{1.7}
$$

#### 终止计算：

$$
P(Y\mid X)=\alpha_T(2U+1)+\alpha_T(2U)  \tag{1.8}
$$

如下图给出英文单词WATSON，首先为其加上空白标签变成"-W-A-T-S-O-N"，其中“-”在图中为方块，字母为圆圈。拓展后$Y^{'}$长度为13，$X$​长度为12，则我们需要计算13*12个中间结果。

<img src="/assets/images/20211013153423.png" alt="img" style="zoom:80%;" />

根据公式1.7，方块只能向前或向上移动一格，即不能跳到下一个空白字符。而实心圆圈除了可以向前或向上移动一格外，如果和下一个字母不同，也可以向上移动两格。

<img src="/assets/images/20211013153559.png" style="zoom:83%;" />

<img src="/assets/images/20211013153622.png" alt="img" style="zoom:80%;" />

### 后向算法

后向算法由后向前推算输出概率。用$\beta_t(s)$表示在t时刻的标签为s及输出观察概率为$x_t,x_{t+1},...,x_T$
$$
\beta_t(s)=P(x_t,x_{t+1}，...,x_T) \tag{1.9}
$$
扩展输出序列$Y'=b,y_1,b,y_2,...y_u,b\space$的长度为2U+1。则后向算法迭代过程如下：

#### 初始化：

$$
\begin{align}
\beta_T(2U+1) &= P(y'_{2U+1}\mid x_T) \\
\beta_T(2U) &= P(y'_{2U}\mid x_T) \\
\beta_T(s) &= 0,\forall s<2U 
\end{align}
$$

#### 迭代计算：

$$
\beta{t+1}(s)=
\begin{cases}
(\beta_{t+1}(s)+\beta_{t+1}(s+1))P(y'_s\mid x_t), \space if \space y'_s=b \space or \space y'_{s+2}=y'_s\\
(\beta_{t+1}(s)+\beta_{t+1}(s+1)+\beta_{t+2}(s+2))P(y'_s\mid x_t), \space otherwise
\end{cases}
$$





参考资料：

1. 语音识别：原理与应用（洪青阳）
2. https://zhuanlan.zhihu.com/p/42719047
3. https://xiaodu.io/ctc-explained/
